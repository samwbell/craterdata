{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da866033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "from scipy.stats.mstats import gmean\n",
    "from scipy.stats import gamma, poisson, linregress, beta, norm, lognorm\n",
    "from scipy import optimize\n",
    "from scipy import interpolate\n",
    "import time\n",
    "import random\n",
    "import pickle as pkl\n",
    "from cratrcountr import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca554f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_pf(depth_cutoff, sr_Fit, ej_Fit):\n",
    "    def rfunc(logD):\n",
    "        c = np.log10(depth_cutoff)\n",
    "        sr = sr_Fit.apply(logD)\n",
    "        ej = ej_Fit.apply(logD)\n",
    "        a = 30.0\n",
    "        return np.piecewise(\n",
    "            logD, \n",
    "            [logD <= c, logD > c], \n",
    "            [sr[logD <= c], \n",
    "                (sr[logD > c] + a * (logD[logD > c] - c)**3 * ej[logD > c]) / \n",
    "                (1 + a * (logD[logD > c] - c)**3)]\n",
    "        )\n",
    "    return rfunc\n",
    "\n",
    "# def synth_fixed_N_fixed_age(\n",
    "#     N=20, dmin=1, dmax=1E5, n_points=10000,\n",
    "#     pf=loglog_linear_pf(N1=0.001, slope=-2), n_steps=100, age=1\n",
    "# ):\n",
    "#     logD = np.flip(np.linspace(np.log10(dmin), np.log10(dmax), n_points))\n",
    "#     D = 10**logD\n",
    "#     Y = age * (10**pf(logD) - 10**pf(dmax))\n",
    "#     P_cumulative = Y / Y.max()\n",
    "#     synth_list = [np.interp(np.random.random(N), P_cumulative, D)\n",
    "#                   for i in range(n_steps)]\n",
    "#     synth_area = N / (age * (10**pf(np.log10(dmin)) - 10**pf(np.log10(dmax))))\n",
    "#     return synth_list, synth_area\n",
    "\n",
    "def synth_fixed_N_fixed_age(\n",
    "    N=20, dmin=1, dmax=1E5, n_points=10000, area_max=None,\n",
    "    pf=loglog_linear_pf(N1=0.001, slope=-2), n_steps=100, age=1\n",
    "):\n",
    "    logD = np.flip(np.linspace(np.log10(dmin), np.log10(dmax), n_points))\n",
    "    D = 10**logD\n",
    "    Y = age * 10**pf(logD)\n",
    "    synth_area = N / (age * (10**pf(np.log10(dmin))))\n",
    "    if area_max is not None and synth_area > area_max:\n",
    "        N_ef = round(N / (synth_area / area_max))\n",
    "        synth_area = area_max\n",
    "    else:\n",
    "        N_ef = N\n",
    "    P_cumulative = Y / Y.max()\n",
    "    synth_list = [np.interp(np.random.random(N_ef), P_cumulative, D)\n",
    "                  for i in range(n_steps)]\n",
    "    return synth_list, synth_area\n",
    "\n",
    "def plot_rhos(\n",
    "    ds, rhos, area, color='blue', alpha=1.0, ms=4, \n",
    "    ylabel_type=' Cumulative ', label_size=18,\n",
    "    tick_size=20\n",
    "):\n",
    "    lower, upper = get_true_error_bars(np.round(rhos * area, 7))\n",
    "    lower_array, upper_array = lower / area, upper / area\n",
    "    plt.errorbar(ds, rhos, yerr=[lower_array, upper_array],\n",
    "                 color=color, alpha=alpha, fmt='none')\n",
    "    plt.plot(ds, rhos, 's', ms=ms, color=color, alpha=alpha)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.xticks(size=tick_size)\n",
    "    plt.yticks(size=tick_size)\n",
    "    \n",
    "    xmax = np.max(ds)\n",
    "    xmin = np.min(ds)\n",
    "    xrange = np.log10(xmax / xmin)\n",
    "    plt.xlim([xmin / (10**(0.05 * xrange)), xmax * 10**(0.05 * xrange)])\n",
    "    \n",
    "    ymax = np.nanmax(rhos + upper_array)\n",
    "    low = rhos - lower_array\n",
    "    ymin = np.nanmin(low[low > 0])\n",
    "\n",
    "    yrange = np.log10(ymax / ymin)\n",
    "    plt.ylim([ymin / (10**(0.05 * yrange)), ymax * 10**(0.05 * yrange)])\n",
    "    \n",
    "    plt.ylabel(ylabel_type + ' Crater Density\\n(craters/km$^2$)', size=label_size)\n",
    "    plt.xlabel('Crater Diameter (km)', size=label_size)\n",
    "    \n",
    "    plt.grid(which='major', linestyle=':', linewidth=0.5, color='black')\n",
    "    plt.grid(which='minor', linestyle=':', linewidth=0.25, color='gray')\n",
    "\n",
    "def plot_sr(\n",
    "    diameters, area, dmin, depth_cutoff, plot_cutoff=False,\n",
    "    color='blue', ms=2, label_size=14, tick_size=14, alpha=1.0\n",
    "):\n",
    "    raw_ds, rhos = fast_calc_cumulative_unbinned(diameters, area)\n",
    "    ds = center_cumulative_points(raw_ds, d_min=dmin)\n",
    "    dc = depth_cutoff\n",
    "    plot_rhos(ds[ds < dc], rhos[ds < dc], area, color=color, ms=ms,\n",
    "              label_size=label_size, tick_size=label_size, alpha=alpha)\n",
    "    if plot_cutoff and ds[ds > dc].shape[0] > 0:\n",
    "        plot_rhos(ds[ds > dc], rhos[ds > dc], area, color='gray', ms=ms,\n",
    "                  label_size=label_size, tick_size=label_size, alpha=alpha)\n",
    "\n",
    "def plot_ej(\n",
    "    diameters, area, dmin,\n",
    "    color='red', ms=2, label_size=14, tick_size=14, alpha=1.0\n",
    "):\n",
    "    raw_ds, rhos = fast_calc_cumulative_unbinned(diameters, area)\n",
    "    ds = center_cumulative_points(raw_ds, d_min=dmin)\n",
    "    plot_rhos(ds, rhos, area, color=color, ms=ms, alpha=alpha,\n",
    "              label_size=label_size, tick_size=tick_size)\n",
    "\n",
    "def get_fit(\n",
    "    eq, X, Y, uncertainties=None, p0=None, bounds=np.array([-np.inf, np.inf])\n",
    "):\n",
    "    if type(uncertainties) == tuple:\n",
    "        lower, upper = uncertainties\n",
    "        symmetric_uncertainties = (lower + upper) / 2\n",
    "        result, cov = optimize.curve_fit(\n",
    "            eq, X, Y, p0=p0, bounds=bounds, sigma=symmetric_uncertainties,\n",
    "            absolute_sigma=True\n",
    "        )\n",
    "        data_Fit = Fit(eq, result)\n",
    "        continue_iteration = True\n",
    "        iteration_count = 0\n",
    "        switch_count = 5\n",
    "        old_uncertainties = symmetric_uncertainties.copy()\n",
    "        while continue_iteration and (iteration_count < 5):\n",
    "            new_uncertainties = old_uncertainties.copy()\n",
    "            above_data = data_Fit.apply(X) > Y\n",
    "            new_uncertainties[above_data] = upper[np.where(above_data)]\n",
    "            new_uncertainties[~above_data] = lower[np.where(~above_data)]\n",
    "            flipQ = (\n",
    "                np.sum(new_uncertainties != old_uncertainties) > 0\n",
    "            )\n",
    "            if flipQ or (iteration_count == 0):\n",
    "                result, cov = optimize.curve_fit(\n",
    "                    eq, X, Y, p0=p0, bounds=bounds, \n",
    "                    sigma=new_uncertainties, absolute_sigma=True\n",
    "                )\n",
    "            data_Fit = Fit(eq, result)\n",
    "            if not flipQ:\n",
    "                continue_iteration = False\n",
    "                switch_count = iteration_count\n",
    "            old_uncertainties = new_uncertainties.copy()\n",
    "            iteration_count += 1\n",
    "        \n",
    "    else:\n",
    "        result, cov = optimize.curve_fit(\n",
    "            eq, X, Y, p0=p0, bounds=bounds, sigma=uncertainties,\n",
    "            absolute_sigma=True\n",
    "        )\n",
    "    return Fit(eq, result)\n",
    "\n",
    "class CraterCount:\n",
    "    \n",
    "    def __init__(self, logD, logRho, lower, upper):\n",
    "        self.logD = logD\n",
    "        self.logRho = logRho\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        \n",
    "    def scale(self, scale_factor):\n",
    "        return CraterCount(\n",
    "            self.logD, self.logRho - scale_factor, self.lower, self.upper\n",
    "        )\n",
    "    \n",
    "    def scale_to(self, other):\n",
    "        min_i = self.logD.argmin()\n",
    "        logRho_below = np.interp(\n",
    "            self.logD[min_i], \n",
    "            np.flip(other.logD), \n",
    "            np.flip(other.logRho)\n",
    "        )\n",
    "        scale_factor = self.logRho[min_i] - logRho_below\n",
    "        return self.scale(scale_factor)\n",
    "    \n",
    "    def log_plot( \n",
    "            self, color='blue', alpha=1.0, ms=4, ylabel_type='Cumulative ', \n",
    "            label_size=12, tick_size=14, lw=1.0\n",
    "        ):\n",
    "        plt.errorbar(self.logD, self.logRho, yerr=[self.lower, self.upper],\n",
    "                     fmt='none' , color=color, alpha=alpha, lw=lw)\n",
    "        plt.plot(\n",
    "            self.logD[self.lower > 0.1], \n",
    "            self.logRho[self.lower > 0.1], \n",
    "            's', ms=ms, color=color, alpha=alpha\n",
    "        )\n",
    "\n",
    "        plt.xticks(size=tick_size)\n",
    "        plt.yticks(size=tick_size)\n",
    "\n",
    "        xmax = np.max(self.logD)\n",
    "        xmin = np.min(self.logD)\n",
    "        xrange = xmax - xmin\n",
    "        plt.xlim([xmin - 0.05 * xrange, xmax + 0.05 * xrange])\n",
    "\n",
    "        ymax = np.nanmax(self.logRho + self.upper)\n",
    "        low = self.logRho - self.lower\n",
    "        ymin = np.nanmin(low)\n",
    "\n",
    "        yrange = ymax - ymin\n",
    "        plt.ylim([ymin - 0.05 * yrange, ymax + 0.05 * yrange])\n",
    "\n",
    "        plt.ylabel('Log(' + ylabel_type + ' Crater Density (craters/km$^2$))', size=label_size)\n",
    "        plt.xlabel('Log(Crater Diameter (km))', size=label_size)\n",
    "\n",
    "        plt.grid(which='major', linestyle=':', linewidth=0.5, color='black')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth=0.25, color='gray')\n",
    "        \n",
    "def scale_counts(counts):\n",
    "    scaled_counts = []\n",
    "    sorted_counts = sorted(counts, key=lambda x: x.logD.min())\n",
    "    for i in range(len(sorted_counts)):\n",
    "        if i == 0:\n",
    "            scale_factor = sorted_counts[i].logRho.max()\n",
    "            scaled_counts.append(\n",
    "                sorted_counts[i].scale(scale_factor)\n",
    "            )\n",
    "        else:\n",
    "            scaled_counts.append(\n",
    "                sorted_counts[i].scale_to(scaled_counts[i - 1])\n",
    "            )\n",
    "    return scaled_counts\n",
    "\n",
    "def get_CraterCount(diameters, area, dmin, cutoff=None):\n",
    "    raw_ds, rhos = fast_calc_cumulative_unbinned(diameters, area)\n",
    "    ds = center_cumulative_points(raw_ds, d_min=dmin)\n",
    "    if cutoff is None:\n",
    "        log_ds = np.log10(ds)\n",
    "        log_rhos = np.log10(rhos)\n",
    "    else:\n",
    "        log_ds = np.log10(ds[ds < cutoff])\n",
    "        log_rhos = np.log10(rhos[ds < cutoff])\n",
    "    lower, upper = get_true_error_bars_log_space(\n",
    "        np.round(10**log_rhos * area, 7)\n",
    "    )\n",
    "    return CraterCount(log_ds, log_rhos, lower, upper)\n",
    "\n",
    "def fit_scaled_counts(pf, scaled_counts, asymmetric=True):\n",
    "    logD = np.concatenate([count.logD for count in scaled_counts])\n",
    "    logRho = np.concatenate([count.logRho for count in scaled_counts])\n",
    "    lower = np.concatenate([count.lower for count in scaled_counts])\n",
    "    upper = np.concatenate([count.upper for count in scaled_counts])\n",
    "    if asymmetric:\n",
    "        uncertainties=tuple([lower, upper])\n",
    "    else:\n",
    "        uncertainties=(lower + upper) / 2\n",
    "    pf_Fit = get_fit(\n",
    "        pf, logD, logRho, \n",
    "        uncertainties=uncertainties,\n",
    "        p0=npf_new_coefficients\n",
    "    )\n",
    "    return pf_Fit\n",
    "\n",
    "def sf(pf_Fit):\n",
    "    return pf_Fit.apply(0) - np.log10(npf_new(1))[0]\n",
    "\n",
    "def N1(count, pf_Fit):\n",
    "    shift = count.logRho[-1] - pf_Fit.apply(count.logD[-1])\n",
    "    N1_0 = pf_Fit.apply(0)\n",
    "    return N1_0 + shift\n",
    "\n",
    "def N1(count, pf_Fit):\n",
    "    shift = count.logRho.max() - pf_Fit.apply(count.logD.min())\n",
    "    N1_0 = pf_Fit.apply(0)\n",
    "    return N1_0 + shift\n",
    "\n",
    "def cross_correlate(ej_pf_Fit, sr_pf_Fit, ej_counts, sr_counts):\n",
    "\n",
    "    N1_shift = np.mean([\n",
    "        N1(ej_count, ej_pf_Fit) - N1(sr_count, sr_pf_Fit)\n",
    "        for ej_count, sr_count in zip(ej_counts, sr_counts)\n",
    "    ])\n",
    "\n",
    "    sr_pf_Fit_cor = Fit(sr_pf_Fit.fit_eq, sr_pf_Fit.params)\n",
    "    ej_pf_Fit_cor = Fit(ej_pf_Fit.fit_eq, ej_pf_Fit.params)\n",
    "    \n",
    "    sr_sf = sf(sr_pf_Fit)\n",
    "    ej_sf = sf(ej_pf_Fit) - N1_shift\n",
    "\n",
    "    sr_pf_Fit_cor.params[0] -= sr_sf\n",
    "    ej_pf_Fit_cor.params[0] -= ej_sf\n",
    "\n",
    "    return ej_pf_Fit_cor, sr_pf_Fit_cor, N1_shift, sr_sf, ej_sf\n",
    "\n",
    "def cross_correlate2(ej_pf_Fit, sr_pf_Fit, ej_counts, sr_counts):\n",
    "\n",
    "    shift_data = [\n",
    "        N1(ej_count, ej_pf_Fit) - N1(sr_count, sr_pf_Fit)\n",
    "        for ej_count, sr_count in zip(ej_counts, sr_counts)\n",
    "    ]\n",
    "    \n",
    "    shift = np.mean(shift_data)\n",
    "\n",
    "    sr_pf_Fit_cor = Fit(sr_pf_Fit.fit_eq, sr_pf_Fit.params)\n",
    "    ej_pf_Fit_cor = Fit(ej_pf_Fit.fit_eq, ej_pf_Fit.params)\n",
    "    \n",
    "    sr_sf = sf(sr_pf_Fit)\n",
    "    ej_sf = sf(ej_pf_Fit) - shift\n",
    "\n",
    "    sr_pf_Fit_cor.params[0] -= sr_sf\n",
    "    ej_pf_Fit_cor.params[0] -= ej_sf\n",
    "\n",
    "    return ej_pf_Fit_cor, sr_pf_Fit_cor, shift_data, shift, sr_sf, ej_sf\n",
    "\n",
    "class Terrain:\n",
    "    \n",
    "    def __init__(\n",
    "        self, age, pf_Fit, area_max=None, cutoff=None, dmax=1E3\n",
    "    ):\n",
    "        self.age = age\n",
    "        self.pf_Fit = pf_Fit\n",
    "        Ds = 10**np.linspace(-3, 3, 10000)\n",
    "        self.dmin = np.max([\n",
    "            hartmann84_sat_D(age, Ds, pf=pf_Fit.apply),\n",
    "            0.008\n",
    "        ])\n",
    "        self.area_max = area_max\n",
    "        self.cutoff = cutoff\n",
    "        self.dmax = dmax\n",
    "        \n",
    "    def sr_pf(self, sr_Fit, ej_Fit):\n",
    "        return sr_pf(self.cutoff, sr_Fit, ej_Fit)\n",
    "    \n",
    "def sf_Fits(pf_Fit1, pf_Fit2):\n",
    "    return pf_Fit1.apply(0) - pf_Fit2.apply(0)\n",
    "\n",
    "def project_pf_Fit(logD1, logRho1, logD2, pf_Fit):\n",
    "    return logRho1 - (pf_Fit.apply(logD1) - pf_Fit.apply(logD2))\n",
    "\n",
    "def sr2ej_shift(sr_count, ej_count, sr_pf_Fit, ej_pf_Fit):\n",
    "    sr_i = sr_count.logRho.argmax()\n",
    "    ej_i = ej_count.logRho.argmax()\n",
    "    sr_projection = project_pf_Fit(\n",
    "        sr_count.logD[sr_i],\n",
    "        sr_count.logRho[sr_i],\n",
    "        ej_count.logD[ej_i],\n",
    "        ej_pf_Fit\n",
    "    )\n",
    "    sr_shift = ej_count.logRho[ej_i] - sr_projection \n",
    "    ej_projection = project_pf_Fit(\n",
    "        ej_count.logD[ej_i],\n",
    "        ej_count.logRho[ej_i],\n",
    "        sr_count.logD[sr_i],\n",
    "        sr_pf_Fit\n",
    "    )\n",
    "    ej_shift = ej_projection - sr_count.logRho[sr_i]\n",
    "    return np.array([\n",
    "        [sr_count.logD[sr_i], sr_shift], \n",
    "        [ej_count.logD[ej_i], ej_shift]\n",
    "    ])\n",
    "\n",
    "def sr2ej_shift_interp(sr_count, ej_count, sr_pf_Fit, ej_pf_Fit):\n",
    "    sr_i = sr_count.logRho.argmax()\n",
    "    ej_i = ej_count.logRho.argmax()\n",
    "    if ej_count.logD[ej_i] > sr_count.logD[sr_i]:\n",
    "        shift = ej_count.logRho[ej_i] - np.interp(\n",
    "            ej_count.logD[ej_i],\n",
    "            sr_count.logD,\n",
    "            sr_count.logRho\n",
    "        )\n",
    "    else:\n",
    "        shift = np.interp(\n",
    "            sr_count.logD[sr_i],\n",
    "            ej_count.logD,\n",
    "            ej_count.logRho\n",
    "        ) - sr_count.logRho[sr_i]\n",
    "    \n",
    "    return shift\n",
    "\n",
    "def pf_fits(pf_Fits, d):\n",
    "    return np.array([\n",
    "        10**pf_Fit.apply(np.log10(d))\n",
    "        for pf_Fit in pf_Fits\n",
    "    ])\n",
    "\n",
    "def pf_fits_pdf(pf_Fits, d):\n",
    "    return make_pdf_from_samples([\n",
    "        10**pf_Fit.apply(np.log10(d))\n",
    "        for pf_Fit in pf_Fits\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59e4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = 1.62\n",
    "mi = 1000\n",
    "vi = 19000 * np.cos(math.pi / 4)\n",
    "ρi = 2500\n",
    "Y0_ej = 5E5\n",
    "Y0_sr = 1.44E7\n",
    "D_est = 50\n",
    "ρt_ej = 2000\n",
    "ρt_sr = 3000\n",
    "K1_ej = 0.55\n",
    "K1_sr = 1.05\n",
    "μ_ej = 0.42\n",
    "μ_sr = 0.38\n",
    "ν = 1 / 3\n",
    "Kr = 1.1\n",
    "moon = tuple([g, vi, ρi])\n",
    "ej = tuple([K1_ej, μ_ej, ν, Y0_ej, ρt_ej])\n",
    "ej_weak = tuple([K1_ej, μ_ej, ν, 5E4, ρt_ej])\n",
    "sr = tuple([K1_sr, μ_sr, ν, Y0_sr, ρt_sr])\n",
    "\n",
    "μ_ej2 = 0.4\n",
    "μ_sr2 = 0.55\n",
    "Y0_ej2 = 5E5\n",
    "ej2 = tuple([K1_ej, μ_ej2, ν, Y0_ej2, ρt_ej])\n",
    "sr2 = tuple([K1_sr, μ_sr2, ν, Y0_sr, ρt_sr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ac56f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_npf(\n",
    "    ej=ej, sr=sr, moon=moon, mi_array=10**np.linspace(1, 20, 1000)\n",
    "):\n",
    "    ej_D = D(mi_array, *ej, *moon)\n",
    "    sr_D = D(mi_array, *sr, *moon)\n",
    "    d = sr_D / 1000\n",
    "    sr_d = d\n",
    "    sr2ej = np.interp(d, sr_D / 1000, ej_D / sr_D)\n",
    "    f = 1 - np.log10(d[(d >= 0.25) & (d < 2)] / 0.25) / np.log10(2 / 0.25)\n",
    "    sr_shift = np.piecewise(\n",
    "        d, \n",
    "        [d < 0.25, (d >= 0.25) & (d < 2), d >= 2], \n",
    "        [sr2ej[d < 0.25],\n",
    "         (f * sr2ej[(d >= 0.25) & (d < 2)] + (1 - f)),\n",
    "         1]\n",
    "    )\n",
    "\n",
    "    d = ej_D / 1000\n",
    "    ej_d = d\n",
    "    ej2sr = np.interp(d, ej_D / 1000, sr_D / ej_D)\n",
    "    f = np.log10(d[(d >= 0.25) & (d < 2)] / 0.25) / np.log10(2 / 0.25)\n",
    "    ej_shift = np.piecewise(\n",
    "        d, \n",
    "        [d < 0.25, (d >= 0.25) & (d < 2), d >= 2], \n",
    "        [1,\n",
    "         (f * ej2sr[(d >= 0.25) & (d < 2)] + (1 - f)),\n",
    "         ej2sr[d >= 2]]\n",
    "    )\n",
    "\n",
    "    return sr_d, sr_shift, ej_d, ej_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99ec8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_array = 10**np.linspace(0, 20, 1000)\n",
    "sr_d, sr_shift, ej_d, ej_shift = adjust_npf(\n",
    "    ej=ej, sr=sr, moon=moon, mi_array=mi_array\n",
    ")\n",
    "sr_d2, sr_shift2, ej_d2, ej_shift2 = adjust_npf(\n",
    "    ej=ej2, sr=sr2, moon=moon, mi_array=mi_array\n",
    ")\n",
    "\n",
    "ej_D = D(mi_array, *ej, *moon)\n",
    "weak_ej_D = D(mi_array, *ej_weak, *moon)\n",
    "weak_ej_shift = ej_D / weak_ej_D\n",
    "weak_ej_d = weak_ej_D / 1000\n",
    "\n",
    "X = np.log10(sr_d / sr_shift)\n",
    "Y = np.log10(npf_new(sr_d))\n",
    "sr_Fit = get_fit(polynomial_degree_11, X, Y)\n",
    "\n",
    "X = np.log10(ej_d / ej_shift)\n",
    "Y = np.log10(npf_new(ej_d))\n",
    "ej_Fit = get_fit(polynomial_degree_11, X, Y)\n",
    "\n",
    "X = np.log10(weak_ej_d / weak_ej_shift)\n",
    "Y = ej_Fit.apply(np.log10(weak_ej_d))\n",
    "weak_ej_Fit = get_fit(polynomial_degree_11, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af56e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dmax = 1E3\n",
    "res_limit = 0.008\n",
    "# Ds = 10**np.linspace(np.log10(res_limit), np.log10(dmax), 10000)\n",
    "# logDs = np.log10(Ds)\n",
    "\n",
    "age_array = 10**np.linspace(np.log10(0.030), np.log10(10), 13)\n",
    "age_array = np.insert(age_array, 0, 0.004)\n",
    "age_array[2] = 0.040\n",
    "age_array = np.insert(age_array, 14, 30.0)\n",
    "\n",
    "n_terrains = age_array.shape[0]\n",
    "\n",
    "area_maxes_sr = np.array([\n",
    "    10, 20, 10, 400, 200, 300, 200, 500, 700, \n",
    "    600, 1000, 3000, 5000, 15000, 50000\n",
    "])\n",
    "\n",
    "sr_cutoffs = np.array([\n",
    "    0.015, 0.03, 0.015, 0.3,\n",
    "    0.04, 0.03, 0.1, 0.13,\n",
    "    0.25, 0.35, 0.6, 1.0,\n",
    "    1.7, 5.0, 50\n",
    "])\n",
    "\n",
    "ej_terrains = [Terrain(age, ej_Fit, dmax=dmax) for age in age_array]\n",
    "sr_terrains = [\n",
    "    Terrain(age, sr_Fit, area_max=area_max, cutoff=cutoff, dmax=dmax)\n",
    "    for age, area_max, cutoff\n",
    "    in zip(age_array, area_maxes_sr, sr_cutoffs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f68d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetics Generation Runtime: 5.686\n"
     ]
    }
   ],
   "source": [
    "n_steps = 1000\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "if True:\n",
    "\n",
    "    sr_d10s = [synth_fixed_N_fixed_age(\n",
    "        N=2500, dmin=terrain.dmin, area_max=terrain.area_max, \n",
    "        dmax=terrain.dmax, n_points=10000, \n",
    "        pf=terrain.sr_pf(sr_Fit, ej_Fit),\n",
    "        n_steps=n_steps, age=terrain.age\n",
    "    ) for terrain in sr_terrains]\n",
    "\n",
    "    ej_d10s = [synth_fixed_N_fixed_age(\n",
    "        N=2500, dmin=terrain.dmin, dmax=terrain.dmax, \n",
    "        n_points=10000, pf=ej_Fit.apply,\n",
    "        n_steps=n_steps, age=terrain.age\n",
    "    ) for terrain in ej_terrains]\n",
    "    \n",
    "    with open('saved/d10_synth_data.pkl', 'wb') as f:\n",
    "        pkl.dump(tuple([sr_d10s, ej_d10s]), f)\n",
    "        \n",
    "else:\n",
    "    \n",
    "    with open('saved/d10_synth_data.pkl', 'rb') as f:\n",
    "        sr_d10s, ej_d10s = pkl.load(f)\n",
    "\n",
    "t2 = time.time()\n",
    "\n",
    "print('Synthetics Generation Runtime: ' + str(round(t2 - t1, 3)))\n",
    "\n",
    "sr_d10_areas = np.array([sr_d10[1] for sr_d10 in sr_d10s])\n",
    "ej_d10_areas = np.array([ej_d10[1] for ej_d10 in ej_d10s])\n",
    "\n",
    "sr_pf_Fits = []\n",
    "ej_pf_Fits = []\n",
    "sr_sfs = []\n",
    "ej_sfs = []\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    sr_d10_ds = [sr_d10[0][i] for sr_d10 in sr_d10s]\n",
    "    ej_d10_ds = [ej_d10[0][i] for ej_d10 in ej_d10s]\n",
    "\n",
    "    sr_counts = [\n",
    "        get_CraterCount(\n",
    "            diameters, area, terrain.dmin, cutoff=1.4 * terrain.cutoff\n",
    "        )\n",
    "        for diameters, area, terrain\n",
    "        in zip(sr_d10_ds, sr_d10_areas, sr_terrains)\n",
    "    ]\n",
    "    sr_counts_scaled = scale_counts(sr_counts)\n",
    "\n",
    "    ej_counts = [\n",
    "        get_CraterCount(diameters, area, terrain.dmin)\n",
    "        for diameters, area, terrain\n",
    "        in zip(ej_d10_ds, ej_d10_areas, ej_terrains)\n",
    "    ]\n",
    "    ej_counts_scaled = scale_counts(ej_counts)\n",
    "    \n",
    "    sr_pf_Fit_raw = fit_scaled_counts(polynomial_degree_11, sr_counts_scaled)\n",
    "    ej_pf_Fit_raw = fit_scaled_counts(polynomial_degree_11, ej_counts_scaled)\n",
    "    \n",
    "    ej_pf_Fit, sr_pf_Fit, N1_shift, sr_sf, ej_sf = cross_correlate(\n",
    "        ej_pf_Fit_raw, sr_pf_Fit_raw, ej_counts, sr_counts\n",
    "    )\n",
    "    \n",
    "    sr_pf_Fits.append(sr_pf_Fit)\n",
    "    ej_pf_Fits.append(ej_pf_Fit)\n",
    "    sr_sfs.append(sr_sf)\n",
    "    ej_sfs.append(ej_sf)\n",
    "    \n",
    "t2 = time.time()\n",
    "\n",
    "print('Fitting Runtime: ' + format_runtime(t2 - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac43a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('saved/pf_fits.pkl', 'rb') as f:\n",
    "#     sr_pf_Fits_save, ej_pf_Fits_save = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0235a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sr_pf_Fits += sr_pf_Fits_save\n",
    "# ej_pf_Fits += ej_pf_Fits_save\n",
    "sr_pf_Fits_save = sr_pf_Fits\n",
    "ej_pf_Fits_save = ej_pf_Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27651d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010, 1010)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sr_pf_Fits_save), len(sr_pf_Fits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4ab44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('saved/pf_fits.pkl', 'wb') as f:\n",
    "#     pkl.dump(tuple([sr_pf_Fits, ej_pf_Fits]), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704a223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
